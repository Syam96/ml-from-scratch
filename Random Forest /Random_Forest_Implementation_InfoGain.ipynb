{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bade5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np\n",
    "from statistics import mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd141e",
   "metadata": {},
   "source": [
    "The following function splits the data into the rows that go to the left and right child based on the condition. If c_id is a categorical variable, then euqality condition is checked. If c_id is a numerical variable, then less than condition is checked. \"Yes\" condition goes to the left child and \"No\" goes to the right child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce72f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(c_id, split_value, data, schema):\n",
    "    cat_cols, num_cols = schema\n",
    "    if c_id in num_cols:\n",
    "        left_split = [row for row in data if row[c_id] < split_value]\n",
    "        right_split = [row for row in data if row[c_id] >= split_value]\n",
    "    else:\n",
    "        left_split = [row for row in data if row[c_id] == split_value]\n",
    "        right_split = [row for row in data if row[c_id] != split_value]\n",
    "    return left_split, right_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbe8ba",
   "metadata": {},
   "source": [
    "The following two functions, as the name suggests, are to calculate the entropy and information gain, respectively, for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12456b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data, labels):\n",
    "    \n",
    "    total_size = len(data)\n",
    "    if total_size==0:\n",
    "        return(0)\n",
    "    entropy = 0\n",
    "    for label in labels:\n",
    "        label_count = len([row for row in data if row[-1] == label]) # number of rows with target=label\n",
    "        if label_count == 0:\n",
    "            continue\n",
    "        entropy += label_count * np.log(label_count/total_size) # weighted sum\n",
    "    entropy = -entropy/total_size # averaging\n",
    "    return(entropy)\n",
    "\n",
    "def information_gain(left_split, right_split, labels):\n",
    "    \n",
    "    total_size = len(left_split) + len(right_split)\n",
    "    if total_size==0: # if no more data, then stop\n",
    "        return(0)\n",
    "    total_data = left_split + right_split\n",
    "    parent_entropy = entropy(total_data, labels) # parent's entropy\n",
    "    left_entropy = entropy(left_split, labels) # left child's entropy\n",
    "    right_entropy = entropy(right_split, labels) # right child's entropy\n",
    "    ie = parent_entropy - (len(left_split)/total_size)*left_entropy - (len(right_split)/total_size)*right_entropy\n",
    "    return(ie)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86ee02",
   "metadata": {},
   "source": [
    "The following function determines the best decision based on the information gain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a816553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_node(data, num_predictors, labels, schema):\n",
    "    node_options = dict()\n",
    "    for c_id in range(num_predictors):\n",
    "        for row in data:\n",
    "            left_split, right_split = split_data(c_id, row[c_id], data, schema) # split data based on the condition\n",
    "            ie = information_gain(left_split, right_split, labels) # fetch the information gain\n",
    "            node_options[(c_id, row[c_id])] = (ie, left_split, right_split) # storing\n",
    "    if len(node_options) != 0:\n",
    "        # choosing the best decision option (maximum information gain)\n",
    "        (best_c_id, best_split_value), (ie, left_split, right_split) = sorted(node_options.items(), key=lambda item: item[1][0])[-1]\n",
    "        return ({'c_id': best_c_id, 'split_value': best_split_value, 'left_split': left_split, 'right_split': right_split})         \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a3024",
   "metadata": {},
   "source": [
    "The following function splits the root node further into child nodes. It builds the entire tree. It also takes into consideration the max_depth and min_leaf_size parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f2aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_node(node, node_depth, max_depth, min_leaf_size, num_predictors, labels, schema):\n",
    "    \n",
    "    left_split = node['left_split']\n",
    "    right_split = node['right_split']\n",
    "    \n",
    "    if (left_split == []) or (right_split == []): # leaf node\n",
    "        node['left_child'] = mode([row[-1] for row in left_split+right_split])\n",
    "        node['right_child'] = mode([row[-1] for row in left_split+right_split])\n",
    "        return\n",
    "    \n",
    "    if node_depth >= max_depth: # depth limit exceeded, end the split; hence leaf node\n",
    "        node['left_child'] = mode([row[-1] for row in left_split])\n",
    "        node['right_child'] = mode([row[-1] for row in right_split])\n",
    "        return\n",
    "    \n",
    "    if len(left_split) <= min_leaf_size: # size limit exceeded, end the split; hence leaf node\n",
    "        node['left_child'] = mode([row[-1] for row in left_split])\n",
    "    else: # continue with the left child\n",
    "        node['left_child'] = get_decision_node(left_split, num_predictors, labels, schema)\n",
    "        split_node(node['left_child'], node_depth+1, max_depth, min_leaf_size, num_predictors, labels, schema)\n",
    "        \n",
    "    if len(right_split) <= min_leaf_size: # size limit exceeded, end the split; hence leaf node\n",
    "        node['right_child'] = mode([row[-1] for row in right_split])\n",
    "    else: # continue with the right child\n",
    "        node['right_child'] = get_decision_node(right_split, num_predictors, labels, schema)\n",
    "        split_node(node['right_child'], node_depth+1, max_depth, min_leaf_size, num_predictors, labels, schema)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e83ba",
   "metadata": {},
   "source": [
    "The following function builds individual trees, given a dataset, max_depth and min_leaf_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161e903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tree(data, max_depth, min_leaf_size):\n",
    "    labels = np.unique([row[-1] for row in data]) # \n",
    "    num_predictors = len(data[0])-1\n",
    "    \n",
    "    cat_cols = []\n",
    "    num_cols = []\n",
    "    for c in range(len(data[0][:-1])):\n",
    "        if isinstance(data[0][c], str):\n",
    "            cat_cols.append(c)\n",
    "        else:\n",
    "            num_cols.append(c)\n",
    "    \n",
    "    schema = (cat_cols, num_cols)\n",
    "    \n",
    "    tree = get_decision_node(data, num_predictors, labels, schema) # getting the root node\n",
    "    \n",
    "    # splitting the root node further and building the tree\n",
    "    split_node(node=tree, node_depth=1, max_depth=max_depth, min_leaf_size=min_leaf_size, \n",
    "               num_predictors=num_predictors, labels=labels, schema=schema)\n",
    "    \n",
    "    return(tree, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bfc252",
   "metadata": {},
   "source": [
    "The following function builds a random forest by building individual trees from the above functions. \n",
    "* sample_ratio --> The ratio of data to be choses as subset data (for each tree)\n",
    "* n_features --> number of features to be used in a subset (for each tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231387af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, n_estimators, max_depth, min_leaf_size, sample_ratio, n_features):\n",
    "    \n",
    "    random_forest = []\n",
    "    cols_count = len(X_train[0])-1\n",
    "    for i in range(n_estimators):\n",
    "        # subsetting rows with replacement\n",
    "        data_subset_index = np.random.randint(0, len(X_train), round(len(X_train)*sample_ratio))\n",
    "         # subsetting columns without replacement\n",
    "        col_subset_index = sorted(np.random.permutation(cols_count)[:n_features])\n",
    "        data_subset = []\n",
    "        for row_id in data_subset_index: # subsetted rows\n",
    "            old_row = X_train[row_id] # full row\n",
    "            new_row = [old_row[col_id] for col_id in col_subset_index] # subsetted features\n",
    "            new_row.append(old_row[-1]) # adding target value\n",
    "            data_subset.append(new_row)\n",
    "        tree, schema = train_tree(data_subset, max_depth, min_leaf_size) # building a shallow tree with the subsetted data\n",
    "        random_forest.append([col_subset_index, tree, schema])\n",
    "    \n",
    "    return(random_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227cc68",
   "metadata": {},
   "source": [
    "The following are functions to make predictions, given a dataset and a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "960a4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for a single row\n",
    "def predict_row(row, tree, schema):\n",
    "    cat_cols, num_cols = schema\n",
    "    if tree['c_id'] in num_cols: # if a numerical column\n",
    "        if row[tree['c_id']] < tree['split_value']:\n",
    "            if isinstance(tree['left_child'], dict): # if further split exists\n",
    "                y_pred = predict_row(row, tree['left_child'], schema)\n",
    "            else: \n",
    "                y_pred = tree['left_child']\n",
    "        else:\n",
    "            if isinstance(tree['right_child'], dict): # if further split exists\n",
    "                y_pred = predict_row(row, tree['right_child'], schema)\n",
    "            else:\n",
    "                y_pred = tree['right_child']\n",
    "    else:  # if a categorical column\n",
    "        if row[tree['c_id']] == tree['split_value']: \n",
    "            if isinstance(tree['left_child'], dict): # if further split exists\n",
    "                y_pred = predict_row(row, tree['left_child'], schema)\n",
    "            else:\n",
    "                y_pred = tree['left_child']\n",
    "        else:\n",
    "            if isinstance(tree['right_child'], dict): # if further split exists\n",
    "                y_pred = predict_row(row, tree['right_child'], schema)\n",
    "            else:\n",
    "                y_pred = tree['right_child']\n",
    "    return(y_pred)\n",
    "\n",
    "\n",
    "def predict(data, rf):\n",
    "    accuracy = 0\n",
    "    for row in data:\n",
    "        y_true = row[-1]\n",
    "        tree_predictions = []\n",
    "        for tree_info in rf:\n",
    "            col_subset_index = tree_info[0]\n",
    "            tree = tree_info[1] \n",
    "            schema = tree_info[2]\n",
    "            data_row = [row[col_id] for col_id in col_subset_index] # subsetted features\n",
    "            tree_pred = predict_row(data_row, tree, schema)\n",
    "            tree_predictions.append(tree_pred)\n",
    "        y_pred = mode(tree_predictions)\n",
    "        print(\"Individual tree predictions: \", tree_predictions)\n",
    "        print(\"True Label: \", y_true, \" Predicted Label: \", y_pred)\n",
    "        if y_true==y_pred:\n",
    "            accuracy += 1\n",
    "    accuracy = accuracy/len(data)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813bec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy data\n",
    "\n",
    "X_train = [['Y', 'Y', 7, 0],\n",
    "      ['Y', 'N', 12, 0],\n",
    "      ['N', 'Y', 18, 1],\n",
    "      ['N', 'Y', 35, 1],\n",
    "      ['Y', 'Y', 38, 1],\n",
    "      ['Y', 'N', 50, 0],\n",
    "      ['N', 'N', 83, 0]\n",
    "     ]\n",
    "X_test = [['Y', 'Y', 8, 0],\n",
    "      ['Y', 'Y', 12.5, 0],\n",
    "      ['N', 'N', 20, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56ebb122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a random forest\n",
    "rf = random_forest(X_train, n_estimators=5, max_depth=1, min_leaf_size=1, sample_ratio=1, n_features=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb649114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual tree predictions:  [1, 1, 0, 0, 0]\n",
      "True Label:  0  Predicted Label:  0\n",
      "Individual tree predictions:  [0, 0, 0, 0, 0]\n",
      "True Label:  0  Predicted Label:  0\n",
      "Individual tree predictions:  [1, 1, 1, 1, 0]\n",
      "True Label:  1  Predicted Label:  1\n",
      "Individual tree predictions:  [1, 1, 1, 1, 1]\n",
      "True Label:  1  Predicted Label:  1\n",
      "Individual tree predictions:  [1, 1, 1, 0, 1]\n",
      "True Label:  1  Predicted Label:  1\n",
      "Individual tree predictions:  [0, 0, 1, 0, 1]\n",
      "True Label:  0  Predicted Label:  0\n",
      "Individual tree predictions:  [0, 0, 1, 1, 1]\n",
      "True Label:  0  Predicted Label:  1\n",
      "Accuracy:  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "predict(X_train, rf) # training metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13b5ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual tree predictions:  [1, 1, 0, 0, 0]\n",
      "True Label:  0  Predicted Label:  0\n",
      "Individual tree predictions:  [1, 1, 0, 0, 0]\n",
      "True Label:  0  Predicted Label:  0\n",
      "Individual tree predictions:  [0, 0, 1, 1, 0]\n",
      "True Label:  1  Predicted Label:  0\n",
      "Accuracy:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "predict(X_test, rf) # test metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed67524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
